{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deteksi Sarkasme\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re,string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import Counter\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angkadua(teksAwal2):\n",
    "    final2=[]\n",
    "    huruf2=\"\"\n",
    "    for x in range(len(teksAwal2)):\n",
    "        cek2=[i for i in teksAwal2[x]]\n",
    "        for x in range(len(cek2)):\n",
    "            if x==0:\n",
    "                final2.append(cek2[0])\n",
    "                huruf2=cek2[0]\n",
    "            else:\n",
    "                if cek2[x]!=huruf2:\n",
    "                    if cek2[x]==\"2\":\n",
    "                        if(len(final2))==2:\n",
    "                            final2.append(cek2[x-2])\n",
    "                            final2.append(cek2[x-1])\n",
    "                            huruf2=cek2[x]\n",
    "                        elif(len(final2)>2):\n",
    "                            jo=\"\".join(cek2[:2])\n",
    "                            if(jo==\"se\" or jo==\"di\"):\n",
    "                                final2.append(\" \")\n",
    "                                final2=final2+cek2[2:x]\n",
    "                                huruf2=cek2[x]\n",
    "                            else:\n",
    "                                final2.append(\" \")\n",
    "                                final2=final2+cek2[:x]\n",
    "                                huruf2=cek2[x]\n",
    "                        else:\n",
    "                            final2.append(cek2[x])\n",
    "                            huruf2=cek2[x]\n",
    "                    else:\n",
    "                        final2.append(cek2[x])\n",
    "                        huruf2=cek2[x]\n",
    "                else:\n",
    "                    final2.append(cek2[x])\n",
    "                    huruf2=cek2[x]\n",
    "        final2.append(\" \")\n",
    "    hasil = \"\".join(final2).split()\n",
    "    return hasil\n",
    "\n",
    "def hapus_hurufganda(teksAwal):\n",
    "    jml=0\n",
    "    \n",
    "    final=[]\n",
    "    huruf=\"\"\n",
    "    for x in range(len(teksAwal)):\n",
    "        cek=[i for i in teksAwal[x]]\n",
    "        for x in range(len(cek)):\n",
    "            if x==0:\n",
    "                final.append(cek[0])\n",
    "                huruf=cek[0]\n",
    "                jml=1\n",
    "            else:\n",
    "                if cek[x]!=huruf:\n",
    "                    final.append(cek[x])\n",
    "                    huruf=cek[x]\n",
    "                    jml=1\n",
    "                else:\n",
    "                    if jml<2:                    \n",
    "                        final.append(cek[x])\n",
    "                        huruf=cek[x]\n",
    "                        jml+=1\n",
    "        final.append(\" \")\n",
    "    hasil = \"\".join(final).split()\n",
    "    return hasil\n",
    "\n",
    "def hapus_simbolAngka(text):\n",
    "    del_angkadua=angkadua(text)\n",
    "    del_hrfganda=hapus_hurufganda(del_angkadua)\n",
    "    \n",
    "    #hasil=[]\n",
    "    token=del_hrfganda\n",
    "    lte=[\"2g\",\"3g\",\"4g\",\"5g\"]\n",
    "    for i in range(len(token)):\n",
    "        if(token[i] not in lte):\n",
    "            token[i]=re.sub(r\"\\d+\",\" \", token[i])\n",
    "                \n",
    "    for ele in range(len(token)):\n",
    "        token[ele]=token[ele].translate(str.maketrans('', '', string.punctuation))\n",
    "        token[ele] = re.sub('\\W',\"\",token[ele])\n",
    "        token[ele] = re.sub('\\s+',\"\",token[ele])\n",
    "\n",
    "    return token\n",
    "\n",
    "def hapus_emoticon(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    #hapus emoji\n",
    "    CleanEmoji=re.sub(emoji_pattern, \"\", text)\n",
    "    return CleanEmoji\n",
    "\n",
    "\n",
    "\n",
    "def tokenize(kalimat):\n",
    "    return word_tokenize(kalimat)\n",
    "\n",
    "\n",
    "def listokalimat(kalimat):\n",
    "    listToStr = ' '.join(kalimat)\n",
    "    return listToStr\n",
    "\n",
    "\n",
    "def delstopwordID(teks):\n",
    "    return [kata for kata in teks if kata not in list_stopwords]\n",
    "\n",
    "def daftarStopword():\n",
    "    list_stopwords = stopwords.words('indonesian')\n",
    "    ##baca tambahan \n",
    "    my_file = open(\"C:\\\\Users\\\\AhmadYazidMunif\\\\JupiterNotebook\\\\StopWordList.txt\", \"r\")\n",
    "    tambahan = my_file.read()\n",
    "    daftar = tambahan.replace('\\n', ' ').split()\n",
    "    ####\n",
    "    list_stopwords.extend(daftar)\n",
    "    list_stopwords = set(list_stopwords)\n",
    "    return list_stopwords\n",
    "\n",
    "def normal_term():\n",
    "    normalisasi_word = pd.read_excel('C:\\\\Users\\\\AhmadYazidMunif\\\\JupiterNotebook\\\\_normalisasiFix.xlsx')\n",
    "    normalisasi_dict = {}\n",
    "    for index, row in normalisasi_word.iterrows():\n",
    "        if row[0] not in normalisasi_dict:\n",
    "            normalisasi_dict[row[0]] = row[1]\n",
    "    return normalisasi_dict\n",
    "\n",
    "def normalisasi(document):\n",
    "    kalimat=document\n",
    "    for term in range(len(kalimat)):\n",
    "        if kalimat[term] in normalisasi_dict:\n",
    "            kalimat[term]=normalisasi_dict[kalimat[term]]\n",
    "    hasil = \" \".join(kalimat).split()\n",
    "    return hasil\n",
    "\n",
    "def stemming(kalimat):\n",
    "    term_dict={}\n",
    "    for kata in kalimat:\n",
    "        for term in kalimat:\n",
    "            if term not in term_dict:\n",
    "                term_dict[term]=\" \"\n",
    "    temp = list(term_dict)\n",
    "    for x in range(len(temp)):\n",
    "        if temp[x]==\"jaringan\":\n",
    "            term_dict[temp[x]] = temp[x]\n",
    "        elif temp[x]==\"teh\" and temp[x+1]==\"anget\":\n",
    "            term_dict[temp[x]] = temp[x]\n",
    "        else:\n",
    "            term_dict[temp[x]] = stemmer.stem(temp[x])\n",
    "    kalimat=[term_dict[term] for term in kalimat]\n",
    "    #listToStr = ' '.join([str(i) for i in kalimat])\n",
    "    return kalimat\n",
    "\n",
    "\n",
    "list_stopwords = daftarStopword()\n",
    "term_dict={}\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "normalisasi_dict = normal_term()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...... Jumlah Data ...... \n",
      "Total: 1374\n",
      "   Sarkasme  BukanSarkas\n",
      "0       178         1196\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "namaFile='C:\\\\Users\\\\AhmadYazidMunif\\\\JupiterNotebook\\\\#tweet_label.csv'\n",
    "DataTweet= pd.read_csv(namaFile)\n",
    "jumlahData=DataTweet[\"Tweet\"].shape[0] #Jumlah Data\n",
    "jmlSarkas=DataTweet[DataTweet.Label==\"Sarkasme\"].shape[0]\n",
    "jmlNonSarkas=DataTweet[DataTweet.Label==\"BukanSarkas\"].shape[0]\n",
    "d={'Jumlah': [jumlahData], 'Sarkasme': [jmlSarkas],'BukanSarkas':[jmlNonSarkas]}\n",
    "cekJumlah = pd.DataFrame(data=d, columns=['Sarkasme','BukanSarkas'])\n",
    "print('\\n...... Jumlah Data ...... ')\n",
    "print(\"Total:\",jumlahData)\n",
    "print(cekJumlah)\n",
    "ax = cekJumlah.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##-------- Mulai Proses Preprocessing --------##\n",
      "\n",
      "\n",
      "...... Proses Casefolding lowercase, hapus URL...... \n",
      "                                                  Tweet        Label  \\\n",
      "0     @mopuci @collegemenfess Mjb, indogsat 100k 50g...     Sarkasme   \n",
      "1     ini jaringan pas wiken knp kenceng pakee bgttt...     Sarkasme   \n",
      "2     @MNCPlayID sudah lebih dari 16 jam layanan int...  BukanSarkas   \n",
      "3     ⁦@IndiHome⁩ lapor di daerah sukatani tapos dep...  BukanSarkas   \n",
      "4     indosat ngntd kmpa si, ada jaringan tpi browse...     Sarkasme   \n",
      "...                                                 ...          ...   \n",
      "1369  @FirstMediaCares Mohon di percepat yah ka\\r\\nD...  BukanSarkas   \n",
      "1370  @IndiHomeCare Kalo pasang kembali justru penga...  BukanSarkas   \n",
      "1371  @IndiHomeCare internet mati min, jaringan terp...  BukanSarkas   \n",
      "1372  @BiznetHome min kenapa jaringan tiba2 di matik...  BukanSarkas   \n",
      "1373  @FirstMediaCares Tidak ada jaringan min dari j...  BukanSarkas   \n",
      "\n",
      "                                           casefolding1  \n",
      "0      mjb, indogsat 100k 50gb. jaringan lebih ok ju...  \n",
      "1     ini jaringan pas wiken knp kenceng pakee bgttt...  \n",
      "2      sudah lebih dari 16 jam layanan internet dan ...  \n",
      "3     ⁦ ⁩ lapor di daerah sukatani tapos depok serin...  \n",
      "4     indosat ngntd kmpa si, ada jaringan tpi browse...  \n",
      "...                                                 ...  \n",
      "1369   mohon di percepat yah ka dikarenakan sangat b...  \n",
      "1370   kalo pasang kembali justru pengaruh ke jaring...  \n",
      "1371               internet mati min, jaringan terputus  \n",
      "1372   min kenapa jaringan tiba2 di matikan? daerah ...  \n",
      "1373         tidak ada jaringan min dari jam 12 offline  \n",
      "\n",
      "[1374 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def lowRemoveURL(text):\n",
    "    #lowercase\n",
    "    lower=text.lower()\n",
    "    #hapus hastag/mention\n",
    "    HastagRT=re.sub(r\"#(\\w+)|@(\\w+)|(\\brt\\b)\",\" \", lower)\n",
    "    #hapus URL\n",
    "    pola_url = r'http\\S+'\n",
    "    CleanURL=re.sub(pola_url,\" \", HastagRT)\n",
    "    #hapus emoticon\n",
    "    hps_emoji=hapus_emoticon(CleanURL)\n",
    "    #hapus multiWhitespace++, ex: ahh   haa\n",
    "    text = re.sub('\\s+',' ',hps_emoji)\n",
    "    #hasil akhir casefolding\n",
    "    hasil=text\n",
    "    return hasil\n",
    "\n",
    "#============== Start Processing Text\n",
    "print(\"\\n##-------- Mulai Proses Preprocessing --------##\\n\")\n",
    "print('\\n...... Proses Casefolding lowercase, hapus URL...... ')\n",
    "DataTweet['casefolding1'] = DataTweet['Tweet'].apply(lowRemoveURL)\n",
    "print(DataTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...... Tokenisasi ...... \n",
      "                                          Tokenisasi\n",
      "0  [mjb, ,, indogsat, 100k, 50gb, ., jaringan, le...\n",
      "1  [ini, jaringan, pas, wiken, knp, kenceng, pake...\n"
     ]
    }
   ],
   "source": [
    "#==== Tokenisasi : memisahkan kata dalam kalimat\n",
    "print('\\n...... Tokenisasi ...... ')\n",
    "DataTweet['Tokenisasi'] = DataTweet['casefolding1'].apply(tokenize)\n",
    "print(DataTweet[['Tokenisasi']].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...... Proses Casefolding2 hapus angka dan simbol...... \n",
      "                                        casefolding2\n",
      "0  [mjb, , indogsat, k, gb, , jaringan, lebih, ok...\n",
      "1  [ini, jaringan, pas, wiken, knp, kenceng, pake...\n"
     ]
    }
   ],
   "source": [
    "print('\\n...... Proses Casefolding2 hapus angka dan simbol...... ')\n",
    "DataTweet['casefolding2'] = DataTweet['Tokenisasi'].apply(hapus_simbolAngka)\n",
    "print(DataTweet[['casefolding2']].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...... Proses Normalisasi ...... \n",
      "                                         Normalisasi\n",
      "0  [maaf, gabung, bareng, indosat, k, gigabyte, j...\n",
      "1  [ini, jaringan, waktu, minggu, kenapa, cepat, ...\n"
     ]
    }
   ],
   "source": [
    "#============== Normalisasi: kata gaul, singkatan jadi kata baku\n",
    "print('\\n...... Proses Normalisasi ...... ')\n",
    "DataTweet['Normalisasi'] = DataTweet['casefolding2'].apply(normalisasi)\n",
    "print(DataTweet[['Normalisasi']].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...... Proses Stopword Removal ...... \n",
      "                                            Stopword\n",
      "0  [maaf, gabung, bareng, indosat, k, gigabyte, j...\n",
      "1  [jaringan, minggu, cepat, pakai, banget, oi, g...\n",
      "2   [jam, layanan, internet, televisi, jaringan, cc]\n",
      "3  [lapor, daerah, sukatani, tapos, depok, indiho...\n",
      "4  [indosat, ngentot, sih, jaringan, browser, jalan]\n",
      "5           [malas, tidur, jaringan, ngajak, kelahi]\n"
     ]
    }
   ],
   "source": [
    "#==== Stopword Removal : hapus kata yang tidak terlalu penting\n",
    "print('\\n...... Proses Stopword Removal ...... ')\n",
    "DataTweet['Stopword'] = DataTweet['Normalisasi'].apply(delstopwordID)\n",
    "print(DataTweet[['Stopword']].head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "................ Proses Stemming ................ \n",
      "0    [maaf, gabung, bareng, indosat, k, gigabyte, j...\n",
      "1    [jaringan, minggu, cepat, pakai, banget, oi, g...\n",
      "2       [jam, layan, internet, televisi, jaringan, cc]\n",
      "Name: Stemmed, dtype: object\n",
      "\n",
      "==========\n",
      "0    maaf gabung bareng indosat k gigabyte jaringan...\n",
      "1    jaringan minggu cepat pakai banget oi gilir ku...\n",
      "Name: newTweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#==== Stemming : mengurangi dimensi fitur kata/term\n",
    "print('\\n................ Proses Stemming ................ ')\n",
    "DataTweet['Stemmed'] = DataTweet['Stopword'].apply(stemming)\n",
    "print(DataTweet['Stemmed'].head(3))\n",
    "DataTweet['newTweet'] = DataTweet['Stemmed'].apply(listokalimat)\n",
    "print('\\n==========')\n",
    "print(DataTweet['newTweet'].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "................ Hitung TF-IDF ................ \n",
      "          term  rata2bobot\n",
      "535   jaringan    0.105116\n",
      "501   internet    0.053987\n",
      "117     banget    0.046293\n",
      "545      jelek    0.042897\n",
      "1447        ya    0.033473\n",
      "702     lambat    0.032434\n",
      "490   indihome    0.029758\n",
      "\n",
      "================\n",
      "      aamiin  aba  abad  abai  abi  absen  adi  adik     admin  administrator  \\\n",
      "0        0.0  0.0   0.0   0.0  0.0    0.0  0.0   0.0  0.000000            0.0   \n",
      "1        0.0  0.0   0.0   0.0  0.0    0.0  0.0   0.0  0.000000            0.0   \n",
      "2        0.0  0.0   0.0   0.0  0.0    0.0  0.0   0.0  0.000000            0.0   \n",
      "3        0.0  0.0   0.0   0.0  0.0    0.0  0.0   0.0  0.000000            0.0   \n",
      "4        0.0  0.0   0.0   0.0  0.0    0.0  0.0   0.0  0.000000            0.0   \n",
      "...      ...  ...   ...   ...  ...    ...  ...   ...       ...            ...   \n",
      "1369     0.0  0.0   0.0   0.0  0.0    0.0  0.0   0.0  0.000000            0.0   \n",
      "1370     0.0  0.0   0.0   0.0  0.0    0.0  0.0   0.0  0.000000            0.0   \n",
      "1371     0.0  0.0   0.0   0.0  0.0    0.0  0.0   0.0  0.487452            0.0   \n",
      "1372     0.0  0.0   0.0   0.0  0.0    0.0  0.0   0.0  0.244172            0.0   \n",
      "1373     0.0  0.0   0.0   0.0  0.0    0.0  0.0   0.0  0.421101            0.0   \n",
      "\n",
      "      ...   xx        ya  yakin  yaudah   yo  youtube  yuk  zabo  zaman  zoom  \n",
      "0     ...  0.0  0.000000    0.0     0.0  0.0      0.0  0.0   0.0    0.0   0.0  \n",
      "1     ...  0.0  0.000000    0.0     0.0  0.0      0.0  0.0   0.0    0.0   0.0  \n",
      "2     ...  0.0  0.000000    0.0     0.0  0.0      0.0  0.0   0.0    0.0   0.0  \n",
      "3     ...  0.0  0.000000    0.0     0.0  0.0      0.0  0.0   0.0    0.0   0.0  \n",
      "4     ...  0.0  0.000000    0.0     0.0  0.0      0.0  0.0   0.0    0.0   0.0  \n",
      "...   ...  ...       ...    ...     ...  ...      ...  ...   ...    ...   ...  \n",
      "1369  ...  0.0  0.266236    0.0     0.0  0.0      0.0  0.0   0.0    0.0   0.0  \n",
      "1370  ...  0.0  0.000000    0.0     0.0  0.0      0.0  0.0   0.0    0.0   0.0  \n",
      "1371  ...  0.0  0.000000    0.0     0.0  0.0      0.0  0.0   0.0    0.0   0.0  \n",
      "1372  ...  0.0  0.000000    0.0     0.0  0.0      0.0  0.0   0.0    0.0   0.0  \n",
      "1373  ...  0.0  0.000000    0.0     0.0  0.0      0.0  0.0   0.0    0.0   0.0  \n",
      "\n",
      "[1374 rows x 1456 columns]\n"
     ]
    }
   ],
   "source": [
    "#====================== lakukan TF-IDF\n",
    "print('\\n................ Hitung TF-IDF ................ ')\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "vect_docs = tfidf_vect.fit_transform(DataTweet['newTweet'])\n",
    "#print(vect_docs)\n",
    "features_names = tfidf_vect.get_feature_names_out()\n",
    "\n",
    "datane = []\n",
    "means=vect_docs.mean(axis=0)\n",
    "for col, term in enumerate(features_names):\n",
    "    datane.append( (term, means[0,col] ))\n",
    "\n",
    "ranking = pd.DataFrame(datane, columns=['term','rata2bobot'])\n",
    "ranking = ranking.sort_values('rata2bobot', ascending=False)\n",
    "print(ranking.head(7))\n",
    "\n",
    "dense = vect_docs.todense()\n",
    "alist = dense.tolist()\n",
    "print('\\n================')\n",
    "newData = pd.DataFrame(alist,columns=features_names)\n",
    "print(newData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = newData.iloc[:]\n",
    "y= DataTweet[\"Label\"]\n",
    "\n",
    "print('\\n================ Model ================ ')\n",
    "print('\\n================ Pembagian data Training dan Testing ================ ')\n",
    "#============================ K-fold Start\n",
    "print('\\nK - Fold Cross Validation')\n",
    "k=10\n",
    "kf = KFold(n_splits=k)\n",
    "print(\"fold-berjumlah:\",k)\n",
    "kfold=[]\n",
    "temp_akurasi = []\n",
    "it=1\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "for train_index , test_index in kf.split(x):\n",
    "    X_train , X_test = x.iloc[train_index,:],x.iloc[test_index,:]\n",
    "    y_train , y_test = y[train_index] , y[test_index]\n",
    "    print('\\n================ Fold ke -',it)\n",
    "    #print('Data Train\\n',X_train)\n",
    "    #print('Data Test\\n',X_test)\n",
    "    sm = SMOTE(random_state=1)\n",
    "    x_oversample, y_oversample = sm.fit_resample(X_train, y_train)\n",
    "    #setelah resampling dengan SMOTE\n",
    "    jumlah_awal = y_train.shape[0]\n",
    "    cekLabel_awal = Counter(y_train)\n",
    "    jumlah_sm = y_oversample.shape[0]\n",
    "    cekLabel_sm = Counter(y_oversample)\n",
    "    jumlah_tes = y_test.shape[0]\n",
    "    print('Jumlah Data latih sebelum SMOTE =', jumlah_awal)\n",
    "    print('Sarkasme =', cekLabel_awal['Sarkasme'],'BukanSarkas =',cekLabel_awal['BukanSarkas'])\n",
    "    print('Jumlah Data latih setelah SMOTE =', jumlah_sm)\n",
    "    print('Sarkasme =', cekLabel_sm['Sarkasme'],'BukanSarkas =',cekLabel_sm['BukanSarkas'])\n",
    "    print('Jumlah Data Uji =', jumlah_tes)\n",
    "    baseLearn_svm=SVC(probability=True, kernel='linear')\n",
    "    model_adaboost =AdaBoostClassifier(n_estimators=30, base_estimator=baseLearn_svm,learning_rate=0.5)\n",
    "    c=model_adaboost.fit(x_oversample,y_oversample)\n",
    "    Prediksi = model_adaboost.predict(X_test)\n",
    "    \n",
    "    ceklah = pd.DataFrame(columns=['Tweet_Split','Label_Split','Label_Prediksi'])\n",
    "    ceklah['newTweet'] = DataTweet['Tweet'].iloc[test_index]\n",
    "    ceklah['Label'] = DataTweet['Label'].iloc[test_index]\n",
    "    ceklah['LabelPrediksi'] = Prediksi\n",
    "    \n",
    "    jumlahtes = ceklah.shape[0]\n",
    "    positif=\"Sarkasme\"\n",
    "    negatif=\"BukanSarkas\"\n",
    "    for i in range(jumlahtes):\n",
    "        cek=ceklah.iloc[i]\n",
    "        if (cek.Label==positif and cek.LabelPrediksi==positif):\n",
    "            TP+=1\n",
    "        elif(cek.Label==positif and cek.LabelPrediksi==negatif):\n",
    "            FP+=1\n",
    "        elif(cek.Label==negatif and cek.LabelPrediksi==negatif):\n",
    "            TN+=1\n",
    "        elif(cek.Label==negatif and cek.LabelPrediksi==positif):\n",
    "            FN+=1\n",
    "    \n",
    "    print(\"(TP) TruePositif :\",TP,\"\\n(FP) FalsePositif :\",FP,\"\\n(TN) TrueNegatif :\",TN,\"\\n(FN) FalsePNegatif :\",FN)\n",
    "    akurasi=(TP+TN)/(TP+FP+TN+FN)\n",
    "    hasil_akurasi = round(akurasi,3)*100\n",
    "    temp_akurasi.append(hasil_akurasi)\n",
    "    print('Akurasi Fold ke -',it,'=',hasil_akurasi)\n",
    "    kfold.append([jumlahtes,TP,FP,TN,FN,hasil_akurasi])\n",
    "    it=it+1\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "rata2=0\n",
    "for x in range(len(temp_akurasi)):\n",
    "    rata2=rata2+temp_akurasi[x]\n",
    "print(round(rata2/k,3))\n",
    "print(kfold)\n",
    "\n",
    "#============================ K-fold End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
